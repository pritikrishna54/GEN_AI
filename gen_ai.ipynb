{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkmZcXPM5fAdoHvMl63DbW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pritikrishna54/GEN_AI/blob/main/gen_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qjcWFrEuc7Z"
      },
      "outputs": [],
      "source": [
        "# !pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown"
      ],
      "metadata": {
        "id": "NLFLgPqpvZ1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "txL-TniiwWSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY=\"AIzaSyCABehd5i4c2W1ZfO07fDcE6d2o-7F4uBo \"\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "9HKcsnbNwhhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1=genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "ans=model1.generate_content(\"what is gemini ai?\")\n",
        "to_markdown(ans.text)\n"
      ],
      "metadata": {
        "id": "Jrg9qPlgw2gT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "outputId": "fbe95879-c204-4ba0-b298-7191bf4bf04e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Gemini is Google's most powerful and capable AI model, designed to be multimodal from the ground up. This means it's built to understand and process information from various sources, including text, code, audio, images, and video, all natively.\n> \n> Here's a breakdown of what Gemini is and its key features:\n> \n> **What is Gemini?**\n> \n> *   **A Multimodal AI Model:** Gemini is designed to understand and reason across different types of information, like text, code, images, audio, and video.  Think of it as a system that can see a picture, hear a sound, read text about it, and connect those pieces of information in a sophisticated way.\n> \n> *   **Developed by Google AI:** It's the flagship AI model from Google AI, intended to surpass previous models in terms of performance and capabilities.\n> \n> *   **Versatile Applications:** Gemini is intended for a wide range of applications, from improving Google's existing products (like Search, Ads, and Chrome) to powering entirely new AI experiences.  This includes things like:\n>     *   **Natural Language Processing (NLP):**  Understanding and generating human-like text for chatbots, content creation, and translation.\n>     *   **Image and Video Understanding:**  Analyzing images and videos for object recognition, scene understanding, and content moderation.\n>     *   **Code Generation and Understanding:**  Assisting developers with writing, debugging, and understanding code.\n>     *   **Scientific Discovery:**  Helping researchers analyze data, run simulations, and make new discoveries in various fields.\n>     *   **Personalized Experiences:**  Creating more personalized and relevant experiences for users across Google's products.\n> \n> **Key Features and Capabilities:**\n> \n> *   **Multimodality:** As mentioned, Gemini is natively multimodal, meaning it's built from the start to handle different types of data together, not just stitched together afterward. This allows for deeper understanding and more complex reasoning.\n> \n> *   **Advanced Reasoning:**  It's designed for complex reasoning tasks, including problem-solving, planning, and creative generation.\n> \n> *   **Code Proficiency:**  Gemini excels in code generation and understanding, supporting multiple programming languages. It can assist developers in writing, debugging, and optimizing code. Some versions are specifically optimized for coding tasks.\n> \n> *   **Scalability:** Google has developed different versions of Gemini to balance performance and resource efficiency:\n>     *   **Gemini Ultra:** The largest and most capable model, intended for highly complex tasks.  It's designed for data centers and high-end applications.\n>     *   **Gemini Pro:** A more efficient model suitable for a wider range of tasks and applications.  It's powering applications like Google's AI Studio and is integrated into Bard (now Gemini).\n>     *   **Gemini Nano:** Designed for on-device use on smartphones and other devices, enabling offline AI capabilities.\n> \n> *   **Integration with Google Ecosystem:** Gemini is being integrated across Google's products and services to enhance existing features and create new AI-powered experiences.\n> \n> **In summary, Gemini is Google's most advanced multimodal AI model, designed to understand and process information from various sources, excel at complex reasoning and coding tasks, and power a wide range of applications across Google's ecosystem and beyond.**\n"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IMG20240830073336.Image\n",
        "\n",
        "# Replace 'actual/path/to/your/image/download.jpeg' with the actual path to your image file.\n",
        "image_path = 'path/to/your/image.jpg'  # Example: 'images/my_image.jpg'\n",
        "Image = IMG20240830073336(image_path)\n",
        "Image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "HP-rGpNBGepZ",
        "outputId": "ea69381c-fed8-4229-d16c-db1976c50d16",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'IMG20240830073336'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-043c2e32681a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mIMG20240830073336\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Replace 'actual/path/to/your/image/download.jpeg' with the actual path to your image file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'path/to/your/image.jpg'\u001b[0m  \u001b[0;31m# Example: 'images/my_image.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIMG20240830073336\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'IMG20240830073336'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for m in genai.list_models():\n",
        "#   if 'generateContent' in m.supported_generation_methods:\n",
        "#     print(m.name)"
      ],
      "metadata": {
        "id": "ftz-Pr1f3o5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "ZdQkYYtzzFe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(img)\n",
        "\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "id": "WHHULo9MzRh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"solve this math problem step by step in hindi\", img], stream=True)\n",
        "response.resolve()"
      ],
      "metadata": {
        "id": "d5uHqfGvzX5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "id": "g_DGOSYxzfil"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}